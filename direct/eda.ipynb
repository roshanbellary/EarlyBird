{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrieval.db.db_utils import DBUtils\n",
    "url = \"retrieval/db/vector.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBUtils(db_file=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_articles = db.get_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8034\n"
     ]
    }
   ],
   "source": [
    "# find all unique keywords\n",
    "all_keywords = set()\n",
    "for article in all_articles:\n",
    "    for keyword in article[\"keywords\"]:\n",
    "        all_keywords.add(keyword[\"value\"])\n",
    "\n",
    "print(len(all_keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'article': 5905, 'multimedia': 336}\n"
     ]
    }
   ],
   "source": [
    "documents = {\n",
    "\n",
    "}\n",
    "\n",
    "for article in all_articles:\n",
    "    type = article[\"all_data\"][\"document_type\"]\n",
    "    if type not in documents:\n",
    "        documents[type] = 1\n",
    "    else:\n",
    "        documents[type] += 1\n",
    "\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out all 'multimedia' types\n",
    "main_articles = [\n",
    "    article for article in all_articles if article[\"all_data\"][\"document_type\"] != \"multimedia\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Arts', 'Podcasts', 'U.S.', 'T Magazine', 'New York', 'Science', 'Books', 'The Learning Network', 'Travel', 'Lens', 'Real Estate', 'Movies', 'Fashion & Style', 'Obituaries', 'Crosswords & Games', 'Times Insider', 'Food', 'Business Day', 'Climate', 'World', 'Corrections', 'Style', 'Sports', 'Your Money', 'Well', 'Weather', 'Magazine', 'Theater', 'Reader Center', 'The Upshot', 'Opinion', 'Briefing', 'Health', 'Technology'}\n",
      "{'Baseball', 'Americas', 'Media', 'Canada', 'Television', 'Columnists', 'Economy', 'The Headlines', 'Asia Pacific', 'Space & Cosmos', 'Pro Football', 'Pro Basketball', 'Live', 'DealBook', 'Letters', 'The Daily', 'Art & Design', 'Africa', 'Politics', 'Music', 'Books Update', 'Lesson Plans', 'Europe', 'Editorials', 'Middle East', 'Family', 'Australia', 'Eat', 'Contributors', 'Wine, Beer & Cocktails', 'Book Review', 'Skiing', 'Horse Racing', 'Dance', 'Mind', 'Elections', 'Energy & Environment ', 'Move', 'Tennis', 'College Football', 'Personal Tech'}\n",
      "34\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "# get all subsection_name\n",
    "all_subsection_names = set()\n",
    "all_section_names = set()\n",
    "for article in main_articles:\n",
    "    all_section_names.add(article[\"all_data\"][\"section_name\"])\n",
    "\n",
    "    if \"subsection_name\" in article[\"all_data\"]:\n",
    "        all_subsection_names.add(article[\"all_data\"][\"subsection_name\"])\n",
    "\n",
    "print(all_section_names )\n",
    "print(all_subsection_names)\n",
    "\n",
    "print(len(all_section_names))\n",
    "print(len(all_subsection_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1577\n"
     ]
    }
   ],
   "source": [
    "# check for each section, either all articles of that section have a subsection_name or none\n",
    "errors = 0\n",
    "section_map = {\n",
    "\n",
    "}\n",
    "\n",
    "for article in main_articles:\n",
    "    section = article[\"all_data\"][\"section_name\"]\n",
    "    if section not in section_map:\n",
    "        section_map[section] = \"subsection_name\" in article[\"all_data\"] and article[\"all_data\"][\"subsection_name\"] is not None\n",
    "    else:\n",
    "        has_subsection = \"subsection_name\" in article[\"all_data\"] and article[\"all_data\"][\"subsection_name\"] is not None\n",
    "        if has_subsection != section_map[section]:\n",
    "            errors += 1\n",
    "\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7884\n"
     ]
    }
   ],
   "source": [
    "unique_keywords = set()\n",
    "for article in main_articles:\n",
    "    for keyword in article[\"keywords\"]:\n",
    "        unique_keywords.add(keyword[\"value\"])\n",
    "print(len(unique_keywords))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
